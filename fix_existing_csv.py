#!/usr/bin/env python3
"""ä¿®å¤ç°æœ‰ positions.csv æ–‡ä»¶ä¸­çš„ç§‘å­¦è®¡æ•°æ³•é—®é¢˜"""

import csv
import re
from pathlib import Path

def has_scientific_notation(value: str) -> bool:
    """æ£€æŸ¥å­—ç¬¦ä¸²æ˜¯å¦åŒ…å«ç§‘å­¦è®¡æ•°æ³•"""
    return bool(re.search(r'\d+\.?\d*e[+-]?\d+', str(value).lower()))

def convert_scientific_to_int(value: str) -> str:
    """å°è¯•å°†ç§‘å­¦è®¡æ•°æ³•è½¬æ¢ä¸ºæ•´æ•°å­—ç¬¦ä¸²"""
    try:
        # å¦‚æœæ˜¯ç§‘å­¦è®¡æ•°æ³•ï¼Œè½¬æ¢ä¸ºæµ®ç‚¹æ•°å†è½¬ä¸ºæ•´æ•°å­—ç¬¦ä¸²
        if has_scientific_notation(value):
            num = float(value)
            # å¦‚æœæ˜¯æ•´æ•°ï¼Œè½¬æ¢ä¸ºæ•´æ•°å­—ç¬¦ä¸²ï¼ˆå»é™¤å°æ•°ç‚¹ï¼‰
            if num == int(num):
                return str(int(num))
            else:
                # å¦‚æœæœ‰å°æ•°éƒ¨åˆ†ï¼Œä¿ç•™æµ®ç‚¹æ•°æ ¼å¼
                return str(num)
        return value
    except (ValueError, OverflowError):
        # è½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸå€¼
        return value

def fix_csv_file(csv_path: str, backup: bool = True):
    """
    ä¿®å¤ CSV æ–‡ä»¶ä¸­çš„ç§‘å­¦è®¡æ•°æ³•é—®é¢˜

    Args:
        csv_path: CSV æ–‡ä»¶è·¯å¾„
        backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½æ–‡ä»¶
    """
    path = Path(csv_path)

    if not path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return False

    print(f"ğŸ” æ£€æŸ¥æ–‡ä»¶: {csv_path}")

    # è¯»å–æ–‡ä»¶
    with open(path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        fieldnames = reader.fieldnames
        rows = list(reader)

    if not rows:
        print("âš ï¸  æ–‡ä»¶ä¸ºç©ºï¼Œæ— éœ€ä¿®å¤")
        return True

    # æ£€æŸ¥å“ªäº›å­—æ®µåŒ…å«ç§‘å­¦è®¡æ•°æ³•
    fields_with_scientific = set()
    fixed_count = 0

    for row in rows:
        for field, value in row.items():
            if value and has_scientific_notation(value):
                fields_with_scientific.add(field)

    if not fields_with_scientific:
        print("âœ… æœªæ£€æµ‹åˆ°ç§‘å­¦è®¡æ•°æ³•ï¼Œæ— éœ€ä¿®å¤")
        return True

    print(f"âš ï¸  æ£€æµ‹åˆ°ä»¥ä¸‹å­—æ®µåŒ…å«ç§‘å­¦è®¡æ•°æ³•: {fields_with_scientific}")

    # åˆ›å»ºå¤‡ä»½
    if backup:
        backup_path = path.with_suffix('.csv.backup')
        import shutil
        shutil.copy2(path, backup_path)
        print(f"ğŸ“¦ å·²åˆ›å»ºå¤‡ä»½: {backup_path}")

    # ä¿®å¤æ•°æ®
    print("\nğŸ”§ å¼€å§‹ä¿®å¤...")
    for row in rows:
        for field in fields_with_scientific:
            if field in row and row[field]:
                old_value = row[field]
                new_value = convert_scientific_to_int(old_value)
                if old_value != new_value:
                    print(f"  {field}: {old_value} â†’ {new_value}")
                    row[field] = new_value
                    fixed_count += 1

    # å†™å›æ–‡ä»¶ï¼ˆä½¿ç”¨ QUOTE_NONNUMERIC é˜²æ­¢å†æ¬¡å‡ºç°é—®é¢˜ï¼‰
    with open(path, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, quoting=csv.QUOTE_NONNUMERIC)
        writer.writeheader()
        writer.writerows(rows)

    print(f"\nâœ… ä¿®å¤å®Œæˆ! å…±ä¿®å¤ {fixed_count} ä¸ªå­—æ®µ")
    print(f"ğŸ“„ å·²æ›´æ–°æ–‡ä»¶: {csv_path}")

    return True

def main():
    """ä¸»å‡½æ•°"""
    positions_csv = "./data/positions.csv"

    print("=" * 60)
    print("CSV ç§‘å­¦è®¡æ•°æ³•ä¿®å¤å·¥å…·")
    print("=" * 60)
    print()

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(positions_csv).exists():
        print(f"â„¹ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {positions_csv}")
        print("   å¦‚æœè¿™æ˜¯æ–°é¡¹ç›®ï¼Œæ— éœ€ä¿®å¤ã€‚")
        return

    # ä¿®å¤æ–‡ä»¶
    fix_csv_file(positions_csv, backup=True)

    print()
    print("=" * 60)
    print("æç¤º:")
    print("  - å¦‚æœåŸå§‹æ•°æ®å·²æŸåï¼Œå¯èƒ½æ— æ³•å®Œå…¨æ¢å¤")
    print("  - ç§‘å­¦è®¡æ•°æ³•å¦‚ 8.81318e+76 å¯èƒ½å·²ä¸¢å¤±ç²¾åº¦")
    print("  - å»ºè®®æ£€æŸ¥ä¿®å¤åçš„æ•°æ®æ˜¯å¦æ­£ç¡®")
    print("  - å¤‡ä»½æ–‡ä»¶ä¿å­˜ä¸º: positions.csv.backup")
    print("=" * 60)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        exit(1)
